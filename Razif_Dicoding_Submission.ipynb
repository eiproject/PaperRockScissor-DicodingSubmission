{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Razif Dicoding Submission.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPIXWpBcEIjz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a45cb3bd-7ed4-4ce9-fbae-9b6d56bdca56"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Conv2D, MaxPooling2D, ZeroPadding2D, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQptdHenT_LV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNxJUlaaT-qV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_width, img_height = 300//4, 200//4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxXE7kToUAAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paperDir = 'rockpaperscissors/rockpaperscissors/paper/'\n",
        "rockDir = 'rockpaperscissors/rockpaperscissors/rock/'\n",
        "scissorDir = 'rockpaperscissors/rockpaperscissors/scissors/'\n",
        "\n",
        "paperList = os.listdir(paperDir)\n",
        "rockList = os.listdir(rockDir)\n",
        "scissorList = os.listdir(scissorDir)\n",
        "\n",
        "dirTrain = [paperList[:500], rockList[:500], scissorList[:500]]\n",
        "dirValidation = [paperList[500:650], rockList[500:650], scissorList[500:650]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BLGXs0Xvkuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(img_name = None, i = None):\n",
        "    # print(img_name, i)\n",
        "    if i == 0:\n",
        "        img_dir = paperDir\n",
        "    elif i == 1:\n",
        "        img_dir = rockDir\n",
        "    else:\n",
        "        img_dir = scissorDir\n",
        "\n",
        "    img = cv2.imread(img_dir+img_name) # Open image\n",
        "\n",
        "    min_HSV = np.array([0, 60, 40], dtype = \"uint8\")\n",
        "    max_HSV = np.array([33, 255, 255], dtype = \"uint8\")\n",
        "    hsvImg = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    # Skin color detection\n",
        "    binaryImg = cv2.inRange(hsvImg, min_HSV, max_HSV)\n",
        "    masked = cv2.bitwise_and(img, img, mask=binaryImg)\n",
        "    # Mask the skin only \n",
        "    result = cv2.cvtColor(masked, cv2.COLOR_BGR2GRAY)\n",
        "    # resize to desired size\n",
        "    result = cv2.resize(result, (img_width, img_height))\n",
        "    # expand to fit with keras\n",
        "    result = np.expand_dims(result, axis=2)\n",
        "    # print(binaryImg)\n",
        "    # cv2.imshow('See This', result)\n",
        "    # cv2.waitKey(0)\n",
        "\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7Xk1SZcyPBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iTrain = 0\n",
        "fileTrain = []\n",
        "indexTrain = []\n",
        "\n",
        "for dir in dirTrain:\n",
        "    for file in dir:\n",
        "        # print(file, iTrain)\n",
        "        newImage = preprocessing(file, iTrain)\n",
        "        fileTrain.append(newImage)\n",
        "        if iTrain == 0:\n",
        "            indexTrain.append([1,0,0])\n",
        "        elif iTrain == 1:\n",
        "            indexTrain.append([0,1,0])\n",
        "        elif iTrain == 2:\n",
        "            indexTrain.append([0, 0, 1])\n",
        "\n",
        "    iTrain+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaDV9G--yUfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iVal = 0\n",
        "fileValidation = []\n",
        "indexValidation = []\n",
        "\n",
        "for dir in dirValidation:\n",
        "    for file in dir:\n",
        "        newImage = preprocessing(file, iVal)\n",
        "        fileValidation.append(newImage)\n",
        "        if iVal == 0:\n",
        "            indexValidation.append([1,0,0])\n",
        "        elif iVal == 1:\n",
        "            indexValidation.append([0,1,0])\n",
        "        elif iVal == 2:\n",
        "            indexValidation.append([0, 0, 1])\n",
        "    iVal += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue20OSoVyeH3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "94d3e84a-3255-49f0-f100-0c0c434d3daa"
      },
      "source": [
        "print('shape = ', np.shape(fileTrain))\n",
        "print('shape index = ', np.shape(indexTrain))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape =  (1500, 100, 150, 1)\n",
            "shape index =  (1500, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2QHoCVtygQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_train_samples = 500*3\n",
        "nb_validation_samples = 150*3\n",
        "epochs = 15\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhUNGTj3yjIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "# model.add(Input(shape=(100,150,1)))\n",
        "model.add(ZeroPadding2D(padding=(2,2), input_shape=(img_height, img_width, 1)))\n",
        "model.add(Conv2D(32,(5,5),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4, 4), strides= 2))\n",
        "model.add(Conv2D(32, (5, 5),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4, 4), strides= 1))\n",
        "# model.add(Conv2D(64, (5, 5),activation='relu', strides=1))\n",
        "# model.add(Conv2D(128, (5, 5),activation='relu', strides=1))\n",
        "model.add(Flatten())\n",
        "\n",
        "# model.add(Dense(512))\n",
        "# model.add(Activation('relu'))\n",
        "#\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5auEaqUDymEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "            optimizer='SGD',\n",
        "            # optimizer='adam',\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM7xv7v1yn6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        # horizontal_flip=True\n",
        ")\n",
        "train_datagen.fit(x=fileTrain)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    # horizontal_flip=True\n",
        ")\n",
        "validation_datagen.fit(x=fileValidation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFj0VJY5yp_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fileTrain = np.array(fileTrain)\n",
        "indexTrain = np.array(indexTrain)\n",
        "\n",
        "fileValidation = np.array(fileValidation)\n",
        "indexValidation = np.array(indexValidation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egn4iDXGysI7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "25f20c4e-b11f-494f-ac86-d64e1c71dc83"
      },
      "source": [
        "print('shape 2 = ', np.shape(fileTrain))\n",
        "print('shape 2 index = ', np.shape(indexTrain))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape 2 =  (1500, 100, 150, 1)\n",
            "shape 2 index =  (1500, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-dHq7yWytvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7bef03b1-87af-4bb1-dbd3-0d07e8649639"
      },
      "source": [
        "model.fit_generator(\n",
        "    train_datagen.flow(\n",
        "        x=fileTrain,\n",
        "        y=indexTrain,\n",
        "        batch_size=32,\n",
        "    ),\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=train_datagen.flow(\n",
        "        x=fileValidation,\n",
        "        y=indexValidation,\n",
        "        batch_size=32,\n",
        "    ),\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "print(model.summary())\n",
        "# model.save_weights('BismillahFirst-5epochs-W.h5')\n",
        "model.save('model-dicoding-razif.h5')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "46/46 [==============================] - 53s 1s/step - loss: 0.3549 - accuracy: 0.8470 - val_loss: 0.2817 - val_accuracy: 0.8512\n",
            "Epoch 2/15\n",
            "46/46 [==============================] - 53s 1s/step - loss: 0.2755 - accuracy: 0.8862 - val_loss: 0.4950 - val_accuracy: 0.8086\n",
            "Epoch 3/15\n",
            "46/46 [==============================] - 53s 1s/step - loss: 0.2490 - accuracy: 0.8951 - val_loss: 0.2783 - val_accuracy: 0.9019\n",
            "Epoch 4/15\n",
            "46/46 [==============================] - 53s 1s/step - loss: 0.2142 - accuracy: 0.9192 - val_loss: 0.2756 - val_accuracy: 0.8907\n",
            "Epoch 5/15\n",
            "46/46 [==============================] - 53s 1s/step - loss: 0.1820 - accuracy: 0.9260 - val_loss: 0.1482 - val_accuracy: 0.9211\n",
            "Epoch 6/15\n",
            "46/46 [==============================] - 56s 1s/step - loss: 0.1521 - accuracy: 0.9426 - val_loss: 0.1039 - val_accuracy: 0.9139\n",
            "Epoch 7/15\n",
            "46/46 [==============================] - 53s 1s/step - loss: 0.1204 - accuracy: 0.9559 - val_loss: 0.2001 - val_accuracy: 0.9354\n",
            "Epoch 8/15\n",
            "46/46 [==============================] - 53s 1s/step - loss: 0.1171 - accuracy: 0.9571 - val_loss: 0.1034 - val_accuracy: 0.9458\n",
            "Epoch 9/15\n",
            "46/46 [==============================] - 53s 1s/step - loss: 0.1954 - accuracy: 0.9233 - val_loss: 0.2013 - val_accuracy: 0.9450\n",
            "Epoch 10/15\n",
            "46/46 [==============================] - 53s 1s/step - loss: 0.0892 - accuracy: 0.9698 - val_loss: 0.2473 - val_accuracy: 0.9506\n",
            "Epoch 11/15\n",
            "46/46 [==============================] - 53s 1s/step - loss: 0.0764 - accuracy: 0.9728 - val_loss: 0.0589 - val_accuracy: 0.9689\n",
            "Epoch 12/15\n",
            "46/46 [==============================] - 53s 1s/step - loss: 0.0689 - accuracy: 0.9779 - val_loss: 0.1652 - val_accuracy: 0.9530\n",
            "Epoch 13/15\n",
            "46/46 [==============================] - 53s 1s/step - loss: 0.0588 - accuracy: 0.9787 - val_loss: 0.2465 - val_accuracy: 0.9689\n",
            "Epoch 14/15\n",
            "46/46 [==============================] - 53s 1s/step - loss: 0.0474 - accuracy: 0.9846 - val_loss: 0.0588 - val_accuracy: 0.9633\n",
            "Epoch 15/15\n",
            "46/46 [==============================] - 53s 1s/step - loss: 0.0455 - accuracy: 0.9850 - val_loss: 0.0311 - val_accuracy: 0.9617\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "zero_padding2d_1 (ZeroPaddin (None, 104, 154, 1)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 100, 150, 32)      832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 49, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 45, 70, 32)        25632     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 42, 67, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 90048)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               23052544  \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 195       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 23,095,651\n",
            "Trainable params: 23,095,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}